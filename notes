Agent
    Game
    Model

    Training
        state = get_state(game)
        action = get_move(state)
            model.predict()
        reward, game_over , score = game.play_step(action)
        new_state = get_state(game)
        remember
        model.train()

Game (pygame)
    play_step(action)
        reward, game_over, score

Model
    linear_qnet(DQN) (feed forward neural net with few linear layers)
        model.predict(state)
            action

Reward
    Kill Enemy  +10
    Avoid Shot  +5
    Get Killed  -10
    else:       0

Actions
    [shoot, left, up, right, down]

    [1, 0, 0, 0, 0] - shoot
    [0, 1, 0, 0, 0] - left
    [0, 0, 1, 0, 0] - up
    [0, 0, 0, 1, 0] - right
    [0, 0, 0, 0, 1] - down

State (12 Values)

    [danger straight, danger right, danger left, danger behind,
    
    direction left, direction right, direction up, direction down,
    
    enemy left, enemy right, enemy up, enemy down]

    [E  b   b   b   b

        b   b   b   b

        b   b   b   b

        b   b   b   b P] (up)

    [0, 0, 0, 0,
     0, 0, 1, 0,
     1, 0, 1, 0]

Neural Network (Deep) Q Learning

    State (12)    ->    Hidden Layer (n size)   ->   Actions (5)

    Q Value = Quality of action

    0. Init Q value (=init model)
    1. Choose action (model.predict(state)) (or randome move at start of generations)
    2. Perform action
    3. Measure reward
    4. Update Q value (+ train model)
    5. Repeat 2-4

    We need to optimise for a variable

Bellman Equation

    New q Value = Current Q value + Learning Rate[ Reward for taking action + discount rate(Maximum Q state)]

    Q = model.predict(state_0)

    Q_new = R + y*max(Q(state_1))

    Loss = (Q_new - Q)^2 -> Mean Squared Error used in our optimisation


Player Orientation

    # Very cool way to account for orientation when you don't know in which direction you are pointing

    left, up, down, right
    [0, 0, 0, 0]

    but it can be represented as
    [0, 0, 1] # right
    [1, 0, 0] # left
    [0, 1, 0] # up
    [0, 0, 0] # down

    # But could also be used as
    # [1, 1] # up
    # [1, 0] # left
    # [0, 1] # right
    # [0, 0] # down

    How much should the spaceship turn?
    if d_old != d_new:
        delta = d_old - d_new

    if delta == [0, 1, 0], [0, -1, 0], [1, 0, -1], [-1, 0, 1]:
        rotate = 180

    else if delta = [-1, 1, 0], [1, 0, 0], [0, 0, -1], [0, -1, 1]:
        rotate = -90

    else if delta = [0, 1, -1], [0, 0, 1], [-1, 0, 0], [1, -1, 0]:
        rotate = 90